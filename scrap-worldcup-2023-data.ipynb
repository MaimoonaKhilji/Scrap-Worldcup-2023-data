{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7198843,"sourceType":"datasetVersion","datasetId":4163657}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/maimoonakhilji/scrap-worldcup-2023-data?scriptVersionId=155112730\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install isodate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\nimport pandas as pd\nimport datetime\nimport googleapiclient.discovery\nfrom isodate import parse_duration","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:31:34.435432Z","iopub.execute_input":"2023-12-14T08:31:34.43581Z","iopub.status.idle":"2023-12-14T08:31:34.998461Z","shell.execute_reply.started":"2023-12-14T08:31:34.43578Z","shell.execute_reply":"2023-12-14T08:31:34.99739Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set your API key here\nAPI_KEY = ''\nAPI_NAME = 'youtube'\nAPI_VERSION = 'v3'\n\ndef get_channel_name(api_service, channel_id):\n    # Get the channel details, including the channel name\n    request = api_service.channels().list(part='snippet', id=channel_id, key=API_KEY)\n    response = request.execute()\n    \n    if 'items' in response:\n        return response['items'][0]['snippet']['title']\n    else:\n        return None\n\ndef get_videos_in_channel(api_service, channel_id, start_date, end_date):\n    # Convert dates to RFC 3339 format\n    start_date_rfc3339 = start_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n    end_date_rfc3339 = end_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Get video details in the channel within the date range\n    videos = []\n    next_page_token = None\n    \n    while True:\n        request = api_service.search().list(\n            part='id',\n            channelId=channel_id,\n            maxResults=50,  # Maximum of 50 results per page\n            order='date',\n            pageToken=next_page_token,\n            type='video',\n            key=API_KEY,\n            publishedAfter=start_date_rfc3339,\n            publishedBefore=end_date_rfc3339\n        )\n        \n        response = request.execute()\n        \n        if 'items' in response:\n            videos.extend(response['items'])\n        \n        next_page_token = response.get('nextPageToken')\n        \n        if not next_page_token:\n            break\n    \n    return videos\n\ndef get_video_details(api_service, video_id):\n    # Get video details\n    request = api_service.videos().list(\n        part='snippet,statistics,contentDetails',\n        id=video_id,\n        key=API_KEY\n    )\n    response = request.execute()\n    \n    if 'items' in response:\n        return response['items'][0]\n    else:\n        return None\n\ndef main():\n    # Create the YouTube API service\n    api_service = googleapiclient.discovery.build(API_NAME, API_VERSION, developerKey=API_KEY)\n\n    # Read channel IDs from \"YouTube Channels.csv\"\n    with open(\"/kaggle/input/pakistani-sports-channels/sports channels.csv\", mode='r', newline='',encoding='latin-1') as channels_file:\n        csv_reader = csv.DictReader(channels_file)\n\n        for row in csv_reader:\n            channel_id = row['Channel ID']\n            channel_name = get_channel_name(api_service, channel_id)\n\n            # Enter the start and end dates for the date range of Worldcup 2023\n            start_date_str = \"2023-10-05\"\n            end_date_str = \"2023-11-20\"\n                \n            start_date = datetime.datetime.strptime(start_date_str, '%Y-%m-%d')\n            end_date = datetime.datetime.strptime(end_date_str, '%Y-%m-%d')\n                \n                \n            if channel_name:\n                # Get all videos in the channel within the specified date range and with the specified search term\n                videos = get_videos_in_channel(api_service, channel_id, start_date, end_date)\n\n                # Create a CSV file with the channel name\n                csv_file_name = f\"{channel_name}_worldcup2023.csv\"\n\n                with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n                    fieldnames = ['Video Name', 'Video Link', 'View Count', 'Comment Count', 'Channel Name', 'Published Date', 'Like count', 'Dislikes', 'Video Duration', 'Description', 'Tags', 'Category', 'Thumbnail URL']\n                    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n\n                    writer.writeheader()\n\n                    for video in videos:\n                        video_id = video['id']['videoId']\n                        video_details = get_video_details(api_service, video_id)\n\n                        if video_details:\n                            snippet = video_details.get(\"snippet\", {})\n                            statistics = video_details.get(\"statistics\", {})\n                            content_details = video_details.get(\"contentDetails\", {})\n\n                            video_name = snippet.get('title', 'N/A')\n                            video_link = f\"https://www.youtube.com/watch?v={video_id}\"\n                            view_count = statistics.get('viewCount', 'N/A')\n                            comment_count = statistics.get('commentCount', 'N/A')\n                            channel_name = snippet.get('channelTitle', 'N/A')\n                            published_date = snippet.get('publishedAt', 'N/A')\n                            like_count = statistics.get('likeCount', 'N/A')\n                            dislikes = statistics.get('dislikeCount', 'N/A')\n                            video_duration = content_details.get('duration', 'N/A')\n                            description = snippet.get('description', 'N/A')\n                            tags = snippet.get('tags', [])\n                            category = snippet.get('categoryId', 'N/A')\n                            thumbnail_url = snippet.get('thumbnails', {}).get('default', {}).get('url', 'N/A')\n\n                            writer.writerow({'Video Name': video_name, 'Video Link': video_link, 'View Count': view_count,\n                                                 'Comment Count': comment_count, 'Channel Name': channel_name,\n                                                 'Published Date': published_date, 'Like count': like_count, 'Dislikes': dislikes,\n                                                 'Video Duration': video_duration, 'Description': description,\n                                                 'Tags': ','.join(tags), 'Category': category,\n                                                 'Thumbnail URL': thumbnail_url})\n                \n                    print(f\"Video data for '{channel_name}' saved.\")\n            else:\n                print(f\"{channel_name} Channel not found.\")\n    \n    print(f\"All video data saved to '{csv_file_name}'\")\n\nif __name__ == '__main__':\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T08:32:02.310651Z","iopub.execute_input":"2023-12-14T08:32:02.31104Z","iopub.status.idle":"2023-12-14T08:33:05.067817Z","shell.execute_reply.started":"2023-12-14T08:32:02.311007Z","shell.execute_reply":"2023-12-14T08:33:05.066643Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Video data for 'A Sports' saved.\nVideo data for 'Hasna Mana Hai' saved.\nVideo data for 'Har Lamha Purjosh' saved.\nVideo data for 'SAMAA TV' saved.\nVideo data for 'GEO SUPER' saved.\nVideo data for 'SUNO NEWS HD' saved.\nAll video data saved to 'SUNO NEWS HD_worldcup2023.csv'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}